<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="Joachim Wiberg ">
<meta name="description" content="GRE tunnels are useful in many ways. This blog post shows how to set up multicast routing with pimd over a GRE tunnel. To achieve this we will also set up OSPF over GRE with Quagga, because PIM, unlike DVMRP (mrouted), require unicast routing rules to be established.
.----{ Intranet }----. / 192.168.1.0/24 \ / \ .10 / \.20 .--&amp;#39;---. .1 GRE Tunnel .2 .---`--. | |====================| | | R1 | 172.16.16.0/30 | R2 | | | | | &amp;#39;--.---&amp;#39; &amp;#39;------&amp;#39; | .1 | .1 | 10.0.1.0/24 | 10.0.2.0/24 | .2 | .2 .--&amp;#39;---. .--&amp;#39;---. | | | | | C1 | | C2 | | | | | &amp;#39;------&amp;#39; &amp;#39;------&amp;#39; In this post we are using the home WiFi network, 192.168.1.0/24, to hook up the GRE tunnel. It is just as easy to extend this to a big corporate Intranet with more routers between R1 and R2. As long as that IT department takes care of the unicast routing between R1 and R2 so that the GRE tunnel can be established.
" />
<meta name="keywords" content="" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="" />
<link rel="canonical" href="https://troglobit.com/2016/07/05/multicast-routing-with-pim-sm-over-gre/" />


    <title>
        
            Multicast routing with PIM-SM over GRE :: Joachim Wiberg 
        
    </title>





<link rel="stylesheet" href="https://troglobit.com/main.949191c1dcc9c4a887997048b240354e47152016d821198f89448496ba42e491.css" integrity="sha256-lJGRwdzJxKiHmXBIskA1TkcVIBbYIRmPiUSElrpC5JE=">



    <link rel="apple-touch-icon" sizes="180x180" href="https://troglobit.com/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://troglobit.com/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://troglobit.com/favicon-16x16.png">
    <link rel="manifest" href="https://troglobit.com/site.webmanifest">
    <link rel="mask-icon" href="https://troglobit.com/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="https://troglobit.com/favicon.ico">
    <meta name="msapplication-TileColor" content="">


<meta itemprop="name" content="Multicast routing with PIM-SM over GRE">
<meta itemprop="description" content="GRE tunnels are useful in many ways.  This blog post shows how to set up
multicast routing with pimd over a
GRE tunnel.  To achieve this we will also set up OSPF over GRE with
Quagga, because PIM, unlike DVMRP (mrouted),
require unicast routing rules to be established.
       .----{ Intranet }----.
      /    192.168.1.0/24    \
     /                        \
.10 /                          \.20
.--&#39;---. .1  GRE Tunnel  .2 .---`--.
|      |====================|      |
|  R1  |   172.16.16.0/30   |  R2  |
|      |                    |      |
&#39;--.---&#39;                    &#39;------&#39;
   | .1                        | .1 
   |    10.0.1.0/24            |    10.0.2.0/24
   | .2                        | .2 
.--&#39;---.                    .--&#39;---.
|      |                    |      |
|  C1  |                    |  C2  |
|      |                    |      |
&#39;------&#39;                    &#39;------&#39;
In this post we are using the home WiFi network, 192.168.1.0/24, to hook
up the GRE tunnel.  It is just as easy to extend this to a big corporate
Intranet with more routers between R1 and R2.  As long as that IT
department takes care of the unicast routing between R1 and R2 so
that the GRE tunnel can be established."><meta itemprop="datePublished" content="2018-01-23T20:39:36+00:00" />
<meta itemprop="dateModified" content="2018-01-23T20:39:36+00:00" />
<meta itemprop="wordCount" content="1590">
<meta itemprop="keywords" content="" />
<meta name="twitter:card" content="summary"/><meta name="twitter:title" content="Multicast routing with PIM-SM over GRE"/>
<meta name="twitter:description" content="GRE tunnels are useful in many ways.  This blog post shows how to set up
multicast routing with pimd over a
GRE tunnel.  To achieve this we will also set up OSPF over GRE with
Quagga, because PIM, unlike DVMRP (mrouted),
require unicast routing rules to be established.
       .----{ Intranet }----.
      /    192.168.1.0/24    \
     /                        \
.10 /                          \.20
.--&#39;---. .1  GRE Tunnel  .2 .---`--.
|      |====================|      |
|  R1  |   172.16.16.0/30   |  R2  |
|      |                    |      |
&#39;--.---&#39;                    &#39;------&#39;
   | .1                        | .1 
   |    10.0.1.0/24            |    10.0.2.0/24
   | .2                        | .2 
.--&#39;---.                    .--&#39;---.
|      |                    |      |
|  C1  |                    |  C2  |
|      |                    |      |
&#39;------&#39;                    &#39;------&#39;
In this post we are using the home WiFi network, 192.168.1.0/24, to hook
up the GRE tunnel.  It is just as easy to extend this to a big corporate
Intranet with more routers between R1 and R2.  As long as that IT
department takes care of the unicast routing between R1 and R2 so
that the GRE tunnel can be established."/>



    <meta property="og:title" content="Multicast routing with PIM-SM over GRE" />
<meta property="og:description" content="GRE tunnels are useful in many ways.  This blog post shows how to set up
multicast routing with pimd over a
GRE tunnel.  To achieve this we will also set up OSPF over GRE with
Quagga, because PIM, unlike DVMRP (mrouted),
require unicast routing rules to be established.
       .----{ Intranet }----.
      /    192.168.1.0/24    \
     /                        \
.10 /                          \.20
.--&#39;---. .1  GRE Tunnel  .2 .---`--.
|      |====================|      |
|  R1  |   172.16.16.0/30   |  R2  |
|      |                    |      |
&#39;--.---&#39;                    &#39;------&#39;
   | .1                        | .1 
   |    10.0.1.0/24            |    10.0.2.0/24
   | .2                        | .2 
.--&#39;---.                    .--&#39;---.
|      |                    |      |
|  C1  |                    |  C2  |
|      |                    |      |
&#39;------&#39;                    &#39;------&#39;
In this post we are using the home WiFi network, 192.168.1.0/24, to hook
up the GRE tunnel.  It is just as easy to extend this to a big corporate
Intranet with more routers between R1 and R2.  As long as that IT
department takes care of the unicast routing between R1 and R2 so
that the GRE tunnel can be established." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://troglobit.com/2016/07/05/multicast-routing-with-pim-sm-over-gre/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2018-01-23T20:39:36+00:00" />
<meta property="article:modified_time" content="2018-01-23T20:39:36+00:00" />





    <meta property="article:section" content="UNIX" />

    <meta property="article:section" content="multicast" />

    <meta property="article:section" content="PIM" />



    <meta property="article:published_time" content="2018-01-23 20:39:36 &#43;0000 UTC" />











    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://troglobit.com/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">&gt;</span>
            <span class="logo__text ">
                $ cd /home/</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://troglobit.com/about/">About</a></li><li><a href="https://troglobit.com/posts/">Blog</a></li><li><a href="https://troglobit.com/howtos/">HowTos</a></li><li><a href="https://troglobit.com/projects/">Projects</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        8 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://troglobit.com/2016/07/05/multicast-routing-with-pim-sm-over-gre/">Multicast routing with PIM-SM over GRE</a>
      </h1>

      

      

      

      <div class="post-content">
        <p>GRE tunnels are useful in many ways.  This blog post shows how to set up
multicast routing with <a href="https://github.com/troglobit/pimd/">pimd</a> over a
GRE tunnel.  To achieve this we will also set up OSPF over GRE with
<a href="http://www.quagga.net">Quagga</a>, because PIM, unlike DVMRP (<code>mrouted</code>),
require unicast routing rules to be established.</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>       .----{ Intranet }----.
</span></span><span style="display:flex;"><span>      /    192.168.1.0/24    \
</span></span><span style="display:flex;"><span>     /                        \
</span></span><span style="display:flex;"><span>.10 /                          \.20
</span></span><span style="display:flex;"><span>.--&#39;---. .1  GRE Tunnel  .2 .---`--.
</span></span><span style="display:flex;"><span>|      |====================|      |
</span></span><span style="display:flex;"><span>|  R1  |   172.16.16.0/30   |  R2  |
</span></span><span style="display:flex;"><span>|      |                    |      |
</span></span><span style="display:flex;"><span>&#39;--.---&#39;                    &#39;------&#39;
</span></span><span style="display:flex;"><span>   | .1                        | .1 
</span></span><span style="display:flex;"><span>   |    10.0.1.0/24            |    10.0.2.0/24
</span></span><span style="display:flex;"><span>   | .2                        | .2 
</span></span><span style="display:flex;"><span>.--&#39;---.                    .--&#39;---.
</span></span><span style="display:flex;"><span>|      |                    |      |
</span></span><span style="display:flex;"><span>|  C1  |                    |  C2  |
</span></span><span style="display:flex;"><span>|      |                    |      |
</span></span><span style="display:flex;"><span>&#39;------&#39;                    &#39;------&#39;
</span></span></code></pre></div><p>In this post we are using the home WiFi network, 192.168.1.0/24, to hook
up the GRE tunnel.  It is just as easy to extend this to a big corporate
Intranet with more routers between <code>R1</code> and <code>R2</code>.  As long as that IT
department takes care of the unicast routing between <code>R1</code> and <code>R2</code> so
that the GRE tunnel can be established.</p>
<p>Now, on router R1 we set up the first GRE tunnel endpoint:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ip tunnel add gre0 mode gre remote 192.168.1.20 <span style="color:#fabd2f">local</span> 192.168.1.10 ttl <span style="color:#d3869b">64</span>
</span></span><span style="display:flex;"><span>ip link <span style="color:#fabd2f">set</span> gre0 multicast on
</span></span><span style="display:flex;"><span>ip link <span style="color:#fabd2f">set</span> gre0 up
</span></span><span style="display:flex;"><span>ip addr add 172.16.16.1/30 dev gre0
</span></span></code></pre></div><p>We do not add any static route for <code>R1</code> to reach the LAN on <code>R2</code> that
<code>C2</code> is connected to, that is for OSPF to add dynamically for us later.
Notice, hower, that we must explicitly enable the multicast flag on the
GRE interface, it is not enabled by default in Linux.</p>
<p>On router <code>R2</code> we can now set up the other side of the GRE tunnel:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>ip tunnel add gre0 mode gre remote 192.168.1.10 <span style="color:#fabd2f">local</span> 192.168.1.20 ttl <span style="color:#d3869b">64</span>
</span></span><span style="display:flex;"><span>ip link <span style="color:#fabd2f">set</span> gre0 multicast on
</span></span><span style="display:flex;"><span>ip link <span style="color:#fabd2f">set</span> gre0 up
</span></span><span style="display:flex;"><span>ip addr add 172.16.16.2/30 dev gre0
</span></span></code></pre></div><p>Setup of OSPF in Debian or Ubuntu distributions is only an <code>apt-get</code>
away followed by enabling the zebra and ospf daemons:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo apt-get install quagga
</span></span><span style="display:flex;"><span>sudo editor /etc/quagga/daemons
</span></span></code></pre></div><p>The idea is to set up an OSPF backbone, area 0, for our routers without
wrecking havoc in the big corporate intranet, which may already run OSPF
&hellip; so OSPF should only talk on the <code>gre0</code> interface, and maybe even the
LAN interfaces towards <code>C1</code> and <code>C2</code> (in case we want to expand on this
example later).  In our setup the routers use <code>wlan0</code> to connect to the
intranet.  We can use the sample configuration files to start from:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>sudo cp /usr/share/doc/quagga/examples/zebra.conf.sample /etc/quagga/zebra.conf
</span></span><span style="display:flex;"><span>sudo cp /usr/share/doc/quagga/examples/ospfd.conf.sample /etc/quagga/ospfd.conf
</span></span></code></pre></div><p>The <code>zebra.conf</code> can be left as-is, just edit the <code>ospfd.conf</code> to look
like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>hostname ospfd
</span></span><span style="display:flex;"><span>password zebra
</span></span><span style="display:flex;"><span>router ospf
</span></span><span style="display:flex;"><span>    passive-interface wlan0
</span></span><span style="display:flex;"><span>    redistribute connected
</span></span><span style="display:flex;"><span>    network 172.16.16.0/30 area 0
</span></span></code></pre></div><p>When the routers have peered, the two clients <code>C1</code> and <code>C2</code> should be
able to (unicast) ping each other.  Telnet into the OSPF daemon using
<code>telnet localhost ospfd</code> and type <code>show ip ospf neigh</code> to see all OSPF
neighbors and their status, should be <code>Full/...</code> when done exchanging
routes.  Use <code>show ip ospf route</code> to see the exchanged routes, also
inspect the kernel routing table with <code>route -n</code>.  Use <code>traceroute</code> to
confirm the traffic between clients do traverse the GRE tunnel and not
over the Intranet.</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>root@C1:~$ traceroute 10.0.2.2
</span></span><span style="display:flex;"><span>traceroute to 10.0.2.2 <span style="color:#fe8019">(</span>10.0.2.2<span style="color:#fe8019">)</span>, <span style="color:#d3869b">30</span> hops max, <span style="color:#d3869b">60</span> byte packets
</span></span><span style="display:flex;"><span> <span style="color:#d3869b">1</span>  10.0.1.1 <span style="color:#fe8019">(</span>10.0.1.1<span style="color:#fe8019">)</span>  0.427 ms  0.384 ms  0.309 ms
</span></span><span style="display:flex;"><span> <span style="color:#d3869b">2</span>  172.16.16.2 <span style="color:#fe8019">(</span>172.16.16.2<span style="color:#fe8019">)</span>  3.135 ms  4.724 ms  5.786 ms
</span></span><span style="display:flex;"><span> <span style="color:#d3869b">3</span>  10.0.2.2 <span style="color:#fe8019">(</span>10.0.2.2<span style="color:#fe8019">)</span>  9.979 ms  10.777 ms  10.676 ms
</span></span></code></pre></div><p>Time for <code>pimd</code> to be started.  Just like OSPF we want <code>pimd</code> to avoid
talking on <code>wlan0</code>, so add the following to the default <code>pimd.conf</code>,
which can otherwise be left as-is:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>phyint wlan0 disable
</span></span></code></pre></div><p>In our case the routers have many interfaces, so we disable <em>all</em>
interfaces using the <code>-N</code> switch to <code>pimd</code> and instead only enable the
interfaces we are intrested in, the GRE tunnel and the client LAN
interface, <code>eth0</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>phyint eth0 enable
</span></span><span style="display:flex;"><span>phyint gre0 enable
</span></span></code></pre></div><p>Make sure to add the <code>phyint</code> setting to the correct place in the file.
Now start pimd on each router, use the debug mode and run in foreground
first to see what happens:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>root@R1:~$ pimd -N -f -d
</span></span><span style="display:flex;"><span>debug level 0xffffffff <span style="color:#fe8019">(</span>dvmrp_detail,dvmrp_prunes,dvmrp_routes,dvmrp_neighbors,dvmrp_timers,igmp_proto,igmp_timers,igmp_members,trace,timeout,packets,interfaces,kernel,cache,rsrr,pim_detail,pim_hello,pim_register,pim_join_prune,pim_bootstrap,pim_asserts,pim_cand_rp,pim_routes,pim_timers,pim_rpf<span style="color:#fe8019">)</span>
</span></span><span style="display:flex;"><span>02:01:49.616 pimd version 2.3.2 starting ...
</span></span><span style="display:flex;"><span>02:01:49.617 Got <span style="color:#d3869b">262144</span> byte send buffer size in <span style="color:#d3869b">0</span> iterations
</span></span><span style="display:flex;"><span>02:01:49.617 Got <span style="color:#d3869b">262144</span> byte recv buffer size in <span style="color:#d3869b">0</span> iterations
</span></span><span style="display:flex;"><span>02:01:49.617 Got <span style="color:#d3869b">262144</span> byte send buffer size in <span style="color:#d3869b">0</span> iterations
</span></span><span style="display:flex;"><span>02:01:49.617 Got <span style="color:#d3869b">262144</span> byte recv buffer size in <span style="color:#d3869b">0</span> iterations
</span></span><span style="display:flex;"><span>02:01:49.617 Getting vifs from kernel
</span></span><span style="display:flex;"><span>02:01:49.618 /etc/pimd.conf:0 - Skipping interface lo, either loopback or does not support multicast.
</span></span></code></pre></div><p>&hellip; and on <code>R2</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>root@R2:~$ pimd -N -f -d
</span></span><span style="display:flex;"><span>debug level 0xffffffff <span style="color:#fe8019">(</span>dvmrp_detail,dvmrp_prunes,dvmrp_routes,dvmrp_neighbors,dvmrp_timers,igmp_proto,igmp_timers,igmp_members,trace,timeout,packets,interfaces,kernel,cache,rsrr,pim_detail,pim_hello,pim_register,pim_join_prune,pim_bootstrap,pim_asserts,pim_cand_rp,pim_routes,pim_timers,pim_rpf<span style="color:#fe8019">)</span>
</span></span><span style="display:flex;"><span>02:01:49.616 pimd version 2.3.2 starting ...
</span></span><span style="display:flex;"><span>02:01:49.617 Got <span style="color:#d3869b">262144</span> byte send buffer size in <span style="color:#d3869b">0</span> iterations
</span></span><span style="display:flex;"><span>02:01:49.617 Got <span style="color:#d3869b">262144</span> byte recv buffer size in <span style="color:#d3869b">0</span> iterations
</span></span><span style="display:flex;"><span>02:01:49.617 Got <span style="color:#d3869b">262144</span> byte send buffer size in <span style="color:#d3869b">0</span> iterations
</span></span><span style="display:flex;"><span>02:01:49.617 Got <span style="color:#d3869b">262144</span> byte recv buffer size in <span style="color:#d3869b">0</span> iterations
</span></span><span style="display:flex;"><span>02:01:49.617 Getting vifs from kernel
</span></span><span style="display:flex;"><span>02:01:49.618 /etc/pimd.conf:0 - Skipping interface lo, either loopback or does not support multicast.
</span></span></code></pre></div><p>To verify multicast routing works we start a multicast sender on <code>C1</code>
and a receiver (sink) on <code>C2</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>root@C1:~$ mcjoin -s -t <span style="color:#d3869b">10</span>
</span></span><span style="display:flex;"><span>root@C2:~$ mcjoin
</span></span><span style="display:flex;"><span>.................o
</span></span></code></pre></div><p>Notice the TTL adjustment (<code>-t 10</code>) on the sender side, this is needed
because the default TTL for multicast, due to safety concerns, is 1.</p>
<p>The log on the routers should look something like this (snippet):</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>01:44:16.750 accept_group_report(): igmp_src 10.0.2.2 ssm_src 0.0.0.0 group 225.1.2.3 report_type 34
</span></span><span style="display:flex;"><span>01:44:16.750 Set delete timer for group: 225.1.2.3
</span></span><span style="display:flex;"><span>01:44:16.750 Adding vif 4 for group 225.1.2.3
</span></span><span style="display:flex;"><span>01:44:16.877 Received IGMP v3 Membership Report from 172.16.16.1 to 224.0.0.22
</span></span><span style="display:flex;"><span>01:44:16.877 accept_membership_report(): IGMP v3 report, 40 bytes, from 172.16.16.1 to 224.0.0.22 with 4 group records.
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Virtual Interface Table ======================================================
</span></span><span style="display:flex;"><span>Vif  Local Address    Subnet              Thresh  Flags      Neighbors
</span></span><span style="display:flex;"><span>---  ---------------  ------------------  ------  ---------  -----------------
</span></span><span style="display:flex;"><span>  0  192.168.1.123    192.168.1                1  DISABLED
</span></span><span style="display:flex;"><span>  1  172.17.0.1       172.17                   1  DISABLED
</span></span><span style="display:flex;"><span>  2  192.168.122.1    192.168.122              1  DISABLED
</span></span><span style="display:flex;"><span>  3  172.16.16.2      172.16.16/30             1  DR PIM     172.16.16.1
</span></span><span style="display:flex;"><span>  4  10.0.2.1         10.0.2                   1  DR NO-NBR
</span></span><span style="display:flex;"><span>  5  172.16.16.2      register_vif0            1 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Vif  SSM Group        Sources             
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Multicast Routing Table ======================================================
</span></span><span style="display:flex;"><span>----------------------------------- (*,G) ------------------------------------
</span></span><span style="display:flex;"><span>Source           Group            RP Address       Flags
</span></span><span style="display:flex;"><span>---------------  ---------------  ---------------  ---------------------------
</span></span><span style="display:flex;"><span>INADDR_ANY       225.1.2.3        10.0.2.1         WC RP
</span></span><span style="display:flex;"><span>Joined   oifs: ......              
</span></span><span style="display:flex;"><span>Pruned   oifs: ......              
</span></span><span style="display:flex;"><span>Leaves   oifs: ....l.              
</span></span><span style="display:flex;"><span>Asserted oifs: ......              
</span></span><span style="display:flex;"><span>Outgoing oifs: ....o.              
</span></span><span style="display:flex;"><span>Incoming     : .....I              
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TIMERS:  Entry    JP    RS  Assert VIFS:  0  1  2  3  4  5
</span></span><span style="display:flex;"><span>             0    45     0       0        0  0  0  0  0  0
</span></span><span style="display:flex;"><span>----------------------------------- (S,G) ------------------------------------
</span></span><span style="display:flex;"><span>Source           Group            RP Address       Flags
</span></span><span style="display:flex;"><span>---------------  ---------------  ---------------  ---------------------------
</span></span><span style="display:flex;"><span>192.168.64.2     225.1.2.3        10.0.2.1         SPT CACHE SG
</span></span><span style="display:flex;"><span>Joined   oifs: ......              
</span></span><span style="display:flex;"><span>Pruned   oifs: ......              
</span></span><span style="display:flex;"><span>Leaves   oifs: ....l.              
</span></span><span style="display:flex;"><span>Asserted oifs: ......              
</span></span><span style="display:flex;"><span>Outgoing oifs: ....o.              
</span></span><span style="display:flex;"><span>Incoming     : ...I..              
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TIMERS:  Entry    JP    RS  Assert VIFS:  0  1  2  3  4  5
</span></span><span style="display:flex;"><span>           200    55     0       0        0  0  0  0  0  0
</span></span><span style="display:flex;"><span>--------------------------------- (*,*,G) ------------------------------------
</span></span><span style="display:flex;"><span>Number of Groups: 1
</span></span><span style="display:flex;"><span>Number of Cache MIRRORs: 1
</span></span><span style="display:flex;"><span>------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Candidate Rendezvous-Point Set ===============================================
</span></span><span style="display:flex;"><span>RP address       Incoming  Group Prefix        Priority  Holdtime
</span></span><span style="display:flex;"><span>---------------  --------  ------------------  --------  ---------------------
</span></span><span style="display:flex;"><span>10.0.2.1         5         224/4               20        70      
</span></span><span style="display:flex;"><span>10.0.1.1         3         224/4               20        55      
</span></span><span style="display:flex;"><span>169.254.0.1      1         232/8               1         65535   
</span></span><span style="display:flex;"><span>------------------------------------------------------------------------------
</span></span><span style="display:flex;"><span>Current BSR address: 10.0.2.1
</span></span></code></pre></div><p>In normal operation, i.e. without the debug flag <code>-d</code>, the routing table
and other useful PIM information can be queried from the running <code>pimd</code>
by calling it in client mode.  The following is a wrapper for sending a
<code>SIGUSR1</code> signal to the daemon and reading <code>/var/run/pimd/pimd.dump</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-fallback" data-lang="fallback"><span style="display:flex;"><span>root@R2:~$ pimd -r
</span></span><span style="display:flex;"><span>Virtual Interface Table ======================================================
</span></span><span style="display:flex;"><span>Vif  Local Address    Subnet              Thresh  Flags      Neighbors
</span></span><span style="display:flex;"><span>---  ---------------  ------------------  ------  ---------  -----------------
</span></span><span style="display:flex;"><span>  0  192.168.1.123    192.168.1                1  DISABLED
</span></span><span style="display:flex;"><span>  1  172.17.0.1       172.17                   1  DISABLED
</span></span><span style="display:flex;"><span>  2  192.168.122.1    192.168.122              1  DISABLED
</span></span><span style="display:flex;"><span>  3  172.16.16.2      172.16.16/30             1  DR PIM     172.16.16.1    
</span></span><span style="display:flex;"><span>  4  10.0.2.1         10.0.2                   1  DR NO-NBR
</span></span><span style="display:flex;"><span>  5  172.16.16.2      register_vif0            1 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> Vif  SSM Group        Sources             
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>Multicast Routing Table ======================================================
</span></span><span style="display:flex;"><span>----------------------------------- (*,G) ------------------------------------
</span></span><span style="display:flex;"><span>Source           Group            RP Address       Flags
</span></span><span style="display:flex;"><span>---------------  ---------------  ---------------  ---------------------------
</span></span><span style="display:flex;"><span>INADDR_ANY       225.1.2.3        10.0.2.1         WC RP
</span></span><span style="display:flex;"><span>Joined   oifs: ......              
</span></span><span style="display:flex;"><span>Pruned   oifs: ......              
</span></span><span style="display:flex;"><span>Leaves   oifs: ....l.              
</span></span><span style="display:flex;"><span>Asserted oifs: ......              
</span></span><span style="display:flex;"><span>Outgoing oifs: ....o.              
</span></span><span style="display:flex;"><span>Incoming     : .....I              
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TIMERS:  Entry    JP    RS  Assert VIFS:  0  1  2  3  4  5
</span></span><span style="display:flex;"><span>             0    20     0       0        0  0  0  0  0  0
</span></span><span style="display:flex;"><span>----------------------------------- (S,G) ------------------------------------
</span></span><span style="display:flex;"><span>Source           Group            RP Address       Flags
</span></span><span style="display:flex;"><span>---------------  ---------------  ---------------  ---------------------------
</span></span><span style="display:flex;"><span>10.0.1.2         225.1.2.3        10.0.2.1         SPT CACHE SG
</span></span><span style="display:flex;"><span>Joined   oifs: ......              
</span></span><span style="display:flex;"><span>Pruned   oifs: ......              
</span></span><span style="display:flex;"><span>Leaves   oifs: ....l.              
</span></span><span style="display:flex;"><span>Asserted oifs: ......              
</span></span><span style="display:flex;"><span>Outgoing oifs: ....o.              
</span></span><span style="display:flex;"><span>Incoming     : ...I..              
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>TIMERS:  Entry    JP    RS  Assert VIFS:  0  1  2  3  4  5
</span></span><span style="display:flex;"><span>           185    10     0       0        0  0  0  0  0  0
</span></span><span style="display:flex;"><span>--------------------------------- (*,*,G) ------------------------------------
</span></span><span style="display:flex;"><span>Number of Groups: 1
</span></span><span style="display:flex;"><span>Number of Cache MIRRORs: 1
</span></span><span style="display:flex;"><span>------------------------------------------------------------------------------
</span></span></code></pre></div><p>You can also verify that <code>pimd</code> actually sets routes in the kernel
multicast routing table with:</p>
<div class="highlight"><pre tabindex="0" style="color:#ebdbb2;background-color:#282828;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>root@R2:~$ ip mroute
</span></span><span style="display:flex;"><span><span style="color:#fe8019">(</span>10.0.1.2, 225.1.2.3<span style="color:#fe8019">)</span>        Iif: gre0       Oifs: eth0
</span></span></code></pre></div><h2 id="caveats">Caveats</h2>
<p>There are quite a few caveats to watch out for with multicast routing.
Here are a few:</p>
<ol>
<li>Check the TTL of the multicast stream, must be &gt;1 to be routed.
<strong>Rule of thumb:</strong> increase with each router in topology.</li>
<li>Check the MTU of the interfaces in the path.</li>
<li>Check the reverse path, make sure you have unicast connectivity
between end nodes &ndash; PIM requires this to work!</li>
<li>Check the multicast sender&rsquo;s source IP, verify that it&rsquo;s not a
unroutable link-local (169.254) address.</li>
<li>Have the PIM routers peered?  Should list &lsquo;PIM&rsquo; and a neighbor IP
in the output of <code>pimd -r</code>.  If NO-NBR or DISABLED is shown you
have a network or <code>pimd.conf</code> problem.</li>
<li>As of this writing <code>pimd</code> is a bit sensitive to topology changes.
See <a href="https://github.com/troglobit/pimd/issues/79">issue #79</a> for
details and possible future resolution.</li>
</ol>
<p>For other questions, ideas on setting up multicast routing, see the
general <a href="https://troglobit.com/multicast-howto.html">Multicast HowTo</a>, or file a bug report
at <a href="https://github.com/troglobit">GitHub</a></p>
<p>That&rsquo;s it, good luck!</p>
      </div>
    </article>

    <hr />

    <div class="post-info">
      
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-folder meta-icon"><path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path></svg>

        <span class="tag"><a href="https://troglobit.com/categories/unix/">UNIX</a></span>
        <span class="tag"><a href="https://troglobit.com/categories/multicast/">multicast</a></span>
        <span class="tag"><a href="https://troglobit.com/categories/pim/">PIM</a></span>
        
    </p>


      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        1590 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2018-01-23 21:39
        

         
          
        
      </p>
    </div>

    
    <div class="pagination">
        

        <div class="pagination__buttons">
            
            <span class="button previous">
                <a href="https://troglobit.com/post/2018-02-15-slow-down/">
                    <span class="button__icon">←</span>
                    <span class="button__text">Slow Down</span>
                </a>
            </span>
            

            
            <span class="button next">
                <a href="https://troglobit.com/2017/09/19/threads-vs-event-loop--again/">
                    <span class="button__text">Threads vs Event Loop, Again ...</span>
                    <span class="button__icon">→</span>
                </a>
            </span>
            
        </div>
    </div>


    

    

    

  </main>

            </div>

            
                <footer class="footer">
    
    <div class="footer__inner">
        <div class="footer__content">
            <span>&copy; 2006</span>
            <span><a href="https://troglobit.com/">Joachim Wiberg</a></span>
            <span>UNIX&trade; 4Life! &#9994;</span>
            
            
        </div>
    </div>
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="https://troglobit.com/bundle.min.46e438bd2eca7eb6358c700b40f6f56b22ab0b92503ecc11a2d8e4bcc610b8b4da83e5ea3d3e84fdb5f3c3c765744b9f5bbaf43cf5a027910be07ee39a9c12a1.js" integrity="sha512-RuQ4vS7KfrY1jHALQPb1ayKrC5JQPswRotjkvMYQuLTag&#43;XqPT6E/bXzw8dldEufW7r0PPWgJ5EL4H7jmpwSoQ=="></script>




    </body>
</html>
